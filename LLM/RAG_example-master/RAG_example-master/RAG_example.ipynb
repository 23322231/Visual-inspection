{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.79.tar.gz (50.3 MB)\n",
      "     ---------------------------------------- 0.0/50.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/50.3 MB 1.3 MB/s eta 0:00:40\n",
      "     ---------------------------------------- 0.0/50.3 MB 1.3 MB/s eta 0:00:40\n",
      "     --------------------------------------- 0.1/50.3 MB 657.6 kB/s eta 0:01:17\n",
      "     --------------------------------------- 0.1/50.3 MB 726.2 kB/s eta 0:01:10\n",
      "     --------------------------------------- 0.2/50.3 MB 908.0 kB/s eta 0:00:56\n",
      "     ---------------------------------------- 0.3/50.3 MB 1.1 MB/s eta 0:00:46\n",
      "     ---------------------------------------- 0.4/50.3 MB 1.4 MB/s eta 0:00:36\n",
      "     ---------------------------------------- 0.6/50.3 MB 1.7 MB/s eta 0:00:29\n",
      "      --------------------------------------- 0.8/50.3 MB 2.1 MB/s eta 0:00:24\n",
      "      --------------------------------------- 1.1/50.3 MB 2.5 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 1.3/50.3 MB 2.8 MB/s eta 0:00:18\n",
      "     - -------------------------------------- 1.6/50.3 MB 3.0 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 1.6/50.3 MB 3.0 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 1.6/50.3 MB 3.0 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 1.6/50.3 MB 3.0 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 2.1/50.3 MB 2.9 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 2.7/50.3 MB 3.6 MB/s eta 0:00:14\n",
      "     -- ------------------------------------- 2.8/50.3 MB 3.3 MB/s eta 0:00:15\n",
      "     -- ------------------------------------- 3.1/50.3 MB 3.6 MB/s eta 0:00:14\n",
      "     -- ------------------------------------- 3.4/50.3 MB 3.7 MB/s eta 0:00:13\n",
      "     -- ------------------------------------- 3.7/50.3 MB 3.9 MB/s eta 0:00:13\n",
      "     --- ------------------------------------ 4.1/50.3 MB 4.0 MB/s eta 0:00:12\n",
      "     --- ------------------------------------ 4.4/50.3 MB 4.2 MB/s eta 0:00:12\n",
      "     --- ------------------------------------ 4.6/50.3 MB 4.2 MB/s eta 0:00:11\n",
      "     --- ------------------------------------ 4.9/50.3 MB 4.3 MB/s eta 0:00:11\n",
      "     ---- ----------------------------------- 5.2/50.3 MB 4.4 MB/s eta 0:00:11\n",
      "     ---- ----------------------------------- 5.6/50.3 MB 4.5 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 5.9/50.3 MB 4.6 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 6.2/50.3 MB 4.7 MB/s eta 0:00:10\n",
      "     ----- ---------------------------------- 6.5/50.3 MB 4.7 MB/s eta 0:00:10\n",
      "     ----- ---------------------------------- 6.8/50.3 MB 4.8 MB/s eta 0:00:10\n",
      "     ----- ---------------------------------- 7.1/50.3 MB 4.8 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 7.4/50.3 MB 4.9 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 7.7/50.3 MB 4.9 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 8.1/50.3 MB 5.0 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 8.4/50.3 MB 5.0 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 8.7/50.3 MB 5.1 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 9.0/50.3 MB 5.1 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 9.3/50.3 MB 5.2 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 9.6/50.3 MB 5.2 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 9.9/50.3 MB 5.2 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 10.2/50.3 MB 5.3 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 10.5/50.3 MB 6.0 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 10.9/50.3 MB 6.1 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 11.2/50.3 MB 6.1 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 11.5/50.3 MB 6.2 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 11.8/50.3 MB 6.2 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 12.1/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 12.4/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 12.7/50.3 MB 6.5 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 13.0/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 13.4/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 13.7/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 14.0/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 14.3/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 14.6/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 15.0/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ------------ --------------------------- 15.3/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ------------ --------------------------- 15.6/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ------------ --------------------------- 15.9/50.3 MB 6.8 MB/s eta 0:00:06\n",
      "     ------------ --------------------------- 16.2/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 16.5/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 16.8/50.3 MB 6.7 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 17.2/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 17.5/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 17.8/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 18.1/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 18.4/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 18.7/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 19.1/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 19.4/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 19.7/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 20.0/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 20.3/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 20.6/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 20.9/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 21.2/50.3 MB 6.8 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 21.5/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 21.9/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 22.1/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 22.5/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 22.8/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 23.1/50.3 MB 6.7 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 23.4/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 23.7/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 24.0/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 24.3/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 24.6/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 24.9/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 25.2/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 25.5/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 25.8/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 26.1/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 26.5/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 26.8/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 27.1/50.3 MB 6.7 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 27.4/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 27.7/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 28.0/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 28.4/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 28.7/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 29.0/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 29.3/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 29.6/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 29.9/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 30.2/50.3 MB 6.6 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 30.6/50.3 MB 6.6 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 30.9/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 31.2/50.3 MB 6.6 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 31.5/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 31.9/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 32.2/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 32.5/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 32.8/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 33.1/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 33.4/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 33.8/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 34.1/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 34.4/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 34.7/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 35.0/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 35.3/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 35.6/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 36.0/50.3 MB 6.8 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 36.3/50.3 MB 6.8 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 36.6/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 36.8/50.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 37.2/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 37.5/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 37.8/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 38.1/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 38.4/50.3 MB 6.7 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 38.7/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 39.0/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 39.3/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 39.7/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 40.0/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 40.3/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 40.6/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 40.9/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 41.3/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 41.6/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 41.9/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 42.2/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 42.5/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 42.8/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 43.2/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 43.5/50.3 MB 6.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 43.8/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 44.1/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 44.4/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 44.7/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 45.0/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 45.3/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 45.6/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 46.0/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 46.3/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 46.6/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 46.9/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 47.2/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 47.5/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 47.8/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 48.1/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 48.4/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 48.7/50.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  49.1/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  49.4/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  49.7/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  50.0/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  50.3/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  50.3/50.3 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 50.3/50.3 MB 6.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-cpp-python) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.79-cp312-cp312-win_amd64.whl size=3359737 sha256=0a3c04dce499e9e6a1a1d854b3371e30ed660087c2fd1f4effe90c06021db8bb\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\58\\51\\f0\\ec5671c5d5850f600724e6ea4c26c42c222f9e217eb42d4a2c\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.79\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install langchain\n",
    "# %pip install -U langchain-community\n",
    "# %pip install pymupdf\n",
    "# %pip install sentence-transformers\n",
    "# %pip install --upgrade pip\n",
    "# %pip install chromadb\n",
    "%pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(\"Virtual_characters.pdf\")\n",
    "PDF_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=5)\n",
    "all_splits = text_splitter.split_documents(PDF_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
    "                                  model_kwargs=model_kwargs)\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=all_splits, embedding=embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import openai python package. Please install it with `pip install openai`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\chat_models\\openai.py:304\u001b[0m, in \u001b[0;36mChatOpenAI.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from langchain.callbacks.manager import CallbackManager\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from langchain_community.llms import LlamaCpp\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     verbose=True,\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m---> 15\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopenai_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai_api_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://127.0.0.1:8080/v1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:203\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     emit_warning()\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\v1\\main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\chat_models\\openai.py:307\u001b[0m, in \u001b[0;36mChatOpenAI.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import openai python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install openai`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m     )\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m    313\u001b[0m     client_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganization\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_organization\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    322\u001b[0m     }\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import openai python package. Please install it with `pip install openai`."
     ]
    }
   ],
   "source": [
    "# from langchain.callbacks.manager import CallbackManager\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "# from langchain_community.llms import LlamaCpp\n",
    "\n",
    "# llm = LlamaCpp(\n",
    "#     model_path=\"llama-2_q4.gguf\",\n",
    "#     n_gpu_layers=100,\n",
    "#     n_batch=512,\n",
    "#     n_ctx=2048,\n",
    "#     f16_kv=True,\n",
    "#     callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "#     verbose=True,\n",
    "# )\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(openai_api_key='None', openai_api_base='http://127.0.0.1:8080/v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='<<SYS>> \\n    You are a helpful assistant eager to assist with providing better Google search results.\\n    <</SYS>> \\n    \\n    [INST] Provide an answer to the following question in 150 words. Ensure that the answer is informative,             relevant, and concise:\\n            {question} \\n    [/INST]')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.prompt_selector import ConditionalPromptSelector\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "DEFAULT_LLAMA_SEARCH_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"<<SYS>> \n",
    "    You are a helpful assistant eager to assist with providing better Google search results.\n",
    "    <</SYS>> \n",
    "    \n",
    "    [INST] Provide an answer to the following question in 150 words. Ensure that the answer is informative, \\\n",
    "            relevant, and concise:\n",
    "            {question} \n",
    "    [/INST]\"\"\",\n",
    ")\n",
    "\n",
    "DEFAULT_SEARCH_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are a helpful assistant eager to assist with providing better Google search results. \\\n",
    "        Provide an answer to the following question in about 150 words. Ensure that the answer is informative, \\\n",
    "        relevant, and concise: \\\n",
    "        {question}\"\"\",\n",
    ")\n",
    "\n",
    "QUESTION_PROMPT_SELECTOR = ConditionalPromptSelector(\n",
    "    default_prompt=DEFAULT_SEARCH_PROMPT,\n",
    "    conditionals=[(lambda llm: isinstance(llm, LlamaCpp), DEFAULT_LLAMA_SEARCH_PROMPT)],\n",
    ")\n",
    "\n",
    "prompt = QUESTION_PROMPT_SELECTOR.get_prompt(llm)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Taiwan is known for its vibrant culture, rich history, and stunning natural beauty. Some of its notable attractions include the bustling Night Markets, where visitors can sample local street food and buy unique souvenirs; the ancient city of Lukang, with its well-preserved traditional architecture; and the beautiful Taroko National Park, featuring marble cliffs, waterfalls, and hiking trails. Taiwan is also famous for its delicious cuisine, including dishes like beef noodle soup, oyster omelets, and bubble tea. Additionally, Taiwan has a thriving tech industry and is home to many world-renowned brands, making it a hub of innovation and technology."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5102.15 ms\n",
      "llama_print_timings:      sample time =      49.11 ms /   159 runs   (    0.31 ms per token,  3237.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5102.02 ms /    84 tokens (   60.74 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   22931.21 ms /   158 runs   (  145.13 ms per token,     6.89 tokens per second)\n",
      "llama_print_timings:       total time =   28534.12 ms /   242 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is Taiwan known for?',\n",
       " 'text': '  Taiwan is known for its vibrant culture, rich history, and stunning natural beauty. Some of its notable attractions include the bustling Night Markets, where visitors can sample local street food and buy unique souvenirs; the ancient city of Lukang, with its well-preserved traditional architecture; and the beautiful Taroko National Park, featuring marble cliffs, waterfalls, and hiking trails. Taiwan is also famous for its delicious cuisine, including dishes like beef noodle soup, oyster omelets, and bubble tea. Additionally, Taiwan has a thriving tech industry and is home to many world-renowned brands, making it a hub of innovation and technology.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"What is Taiwan known for?\"\n",
    "llm_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      " Based"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on the given context, Alison Hawk is a 28-year-old female researcher.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5102.15 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    24 runs   (    0.28 ms per token,  3543.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3174.29 ms /    24 runs   (  132.26 ms per token,     7.56 tokens per second)\n",
      "llama_print_timings:       total time =    3245.13 ms /    25 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': \"Tell me about Alison Hawk's career and age\",\n",
       " 'result': ' Based on the given context, Alison Hawk is a 28-year-old female researcher.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Tell me about Alison Hawk's career and age\"\n",
    "qa.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
